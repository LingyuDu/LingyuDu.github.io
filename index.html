<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Lingyu Du</title>

    <meta name="author" content="Lingyu Du">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Lingyu Du
                </p>
                <p>I am a Ph.D. candidate in the
                        <a href="https://www.tudelft.nl/ewi/over-de-faculteit/afdelingen/software-technology/embedded-systems">Embedded Systems Group</a>
                        of the <a href="https://www.tudelft.nl/en/eemcs/the-faculty/departments/software-technology">Faculty of Electrical Engineering, Mathematics and Computer Science (EEMCS)</a> at
                        <a href="https://www.tudelft.nl/">Delft University of Technology (TU Delft)</a>, the Netherlands, supervised by
                        <a href="https://guohao.netlify.app/">Dr. Guohao Lan</a> and
                        <a href="https://www.st.ewi.tudelft.nl/koen/index.html">Prof. Dr. Koen Langendoen</a>.
                </p>
                <p>
                  Prior to TU Delft, I obtained my Bachelor's Degree in Automation (<a href="https://future.hit.edu.cn/xyjj/list.htm">Honors School</a>) and Master's degree in Control Science and Engineering in Harbin Institute of Technology, China.
                </p>
                <p style="text-align:center">
                  <a href="mailto:lingyu.du@tudelft.nl">Email</a> &nbsp;/&nbsp;
                  <a href="https://scholar.google.com.hk/citations?user=3jCOwKkAAAAJ&hl=en&authuser=1">Scholar</a> &nbsp;/
                  <a href="https://www.linkedin.com/in/lingyu-du-060961202/">LinkedIn</a> &nbsp;/&nbsp;&nbsp;
                  <a href="https://github.com/LingyuDu">Github</a>
                </p>
              </td>
              <td style="padding:2.5%;width:37%;max-width:37%">
                <a href="images/photo.png"><img style="width:60%;max-width:100%;object-fit: cover;" alt="profile photo" src="images/photo.png" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:16px;width:100%;vertical-align:middle">
                <h2>News</h2>
                <ul>
                  <li>
                    [2025/2/25] Our paper entitled <em>``SecureGaze: Defending Gaze Estimation Against Backdoor Attacks''</em> has been accepted to appear in <strong><b>ACM SenSys 2025</b></strong>. See you in Irvine (if I can get my U.S. visa).
                            </li> <p></p>
                  <li>
                    [2024/10] I presented our work at <strong><b>UbiComp 2024</b></strong> and had a very nice spring vacation in Australia!
                            </li> <p></p>
                  <li>
                    [2024/8/5] Our paper entitled <em>``PrivateGaze: Preserving User Privacy in Black-box Mobile Gaze Tracking Services''</em> has been accepted to appear in <strong><b>ACM IMWUT 2024</b></strong>.
                            </li> <p></p>
                  <li>
                    [2023/7/18] Our paper entitled <em>``FreeGaze: Resource-efficient Gaze Estimation via Frequency-domain Contrastive Learning''</em> has been accepted to appear in <strong><b>EWSN 2023</b></strong>.
                             </li> <p></p>
                </ul>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:16px;width:100%;vertical-align:middle">
                <h2>Research</h2>
                <p>
                  My research primarily focuses on building pervasive gaze estimation systems. My research has explored how to improve resource efficiency and address the potential privacy and security concerns of gaze estimation models. I am also interested in developing gaze-based human-computer interactive systems.
                </p>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>





    <tr onmouseout="private_stop()" onmouseover="private_start()">
      <td style="padding:16px;width:30%;vertical-align:middle">
        <div id="security_video" style="opacity: 1;"> <!-- Default opacity set to 1 -->
          <video width="100%" height="100%" muted autoplay loop>
            <source src="images/SecureGaze.mp4" type="video/mp4">
            Your browser does not support the video tag.
          </video>
        </div>
      </td>
      <td style="padding:8px;width:80%;vertical-align:middle">
        <a href="https://arxiv.org/pdf/2502.20306v1">
          <span class="papertitle">SecureGaze: Defending Gaze Estimation Against Backdoor Attacks</span>
        </a>
        <br>
        <strong>Lingyu Du</strong>,
        <a href="https://liu00222.github.io/">Yupei Liu</a>,
        <a href="https://jinyuan-jia.github.io">Jinyuan Jia</a>,
        <a href="https://guohao.netlify.app">Guohao Lan</a>
        <br>
         <em>The 23rd ACM Conference on Embedded Networked Sensor Systems</em><br>
        <strong><b>ACM SenSys</b></strong>, 2025
        <br>
        <a href="https://github.com/LingyuDu/SecureGaze">project page</a>
        <p></p>
        <p>
          The first work to investigate the backdoor vulnerability of gaze estimation models in both the digital world and the physical world, proposing a framework to identify backdoored gaze estimation models and mitigate backdoor behaviors.
        </p>
      </td>
    </tr>

    <tr onmouseout="private_stop()" onmouseover="private_start()">
      <td style="padding:16px;width:30%;vertical-align:middle">
        <div id="private_video" style="opacity: 1;"> <!-- Default opacity set to 1 -->
          <video width="100%" height="100%" muted autoplay loop>
            <source src="images/PrivateGaze.mp4" type="video/mp4">
            Your browser does not support the video tag.
          </video>
        </div>
      </td>
      <td style="padding:8px;width:80%;vertical-align:middle">
        <a href="https://dl.acm.org/doi/pdf/10.1145/3678595">
          <span class="papertitle">PrivateGaze: Preserving User Privacy in Black-box Mobile Gaze Tracking Services</span>
        </a>
        <br>
        <strong>Lingyu Du</strong>,
        <a href="https://jinyuan-jia.github.io">Jinyuan Jia</a>,
        <a href="https://www.ccmitss.com/zhang">Xucong Zhang</a>,
        <a href="https://guohao.netlify.app">Guohao Lan</a>
        <br>
        <em>Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies</em><br><strong><b>IMWUT</b></strong>, 2024
        <br>
        <a href="https://github.com/LingyuDu/PrivateGaze">project page</a>
        <p></p>
        <p>
          An approach to transform raw images to obfuscated images that do not contain private attributes of users but can be used for effective gaze estimation by black-box models.
        </p>
      </td>
    </tr>


    <tr onmouseout="cat4d_stop()" onmouseover="cat4d_start()">
      <td style="padding:16px;width:30%;vertical-align:middle">
        <div id="cat4d_image" style="opacity: 1;"> <!-- Visible by default -->
          <img src="images/freegaze.png" alt="PrivateGaze Preview" style="width:100%; height:auto;"> <!-- Replaced video with an image -->
        </div>
<!--        <script type="text/javascript">-->
<!--          function cat4d_start() {-->
<!--            document.getElementById('cat4d_image').style.opacity = "1";-->
<!--          }-->

<!--          function cat4d_stop() {-->
<!--            document.getElementById('cat4d_image').style.opacity = "0"; // Dim slightly-->
<!--          }-->
<!--        </script>-->
      </td>
      <td style="padding:8px;width:70%;vertical-align:middle">
        <a href="https://dl.acm.org/doi/10.5555/3639940.3639949">
          <span class="papertitle">FreeGaze: Resource-efficient Gaze Estimation via Frequency-domain Contrastive Learning</span>
        </a>
        <br>
        <strong>Lingyu Du</strong>,
        <a href="https://guohao.netlify.app">Guohao Lan</a>
        <br>
        <em>The 20th International Conference on Embedded Wireless Systems and Networks</em><br> <strong><b>EWSN</b></strong>, 2023
        <br>
        <a href="https://github.com/FreeGaze/FreeGaze-Source">project page</a>
        <p></p>
        <p>
          An approach that  can achieve comparable gaze-estimation accuracy with the existing supervised learning-based approach, while enabling up to 6.81 and 1.67 times speedup in system calibration and inference, respectively.
        </p>
      </td>
    </tr>





<!--          </tbody></table>-->

<!--          -->
<!--					<table style="width:100%; margin:0 auto; border:0; border-spacing:0; padding:16px;"><tbody>-->
<!--            <tr>-->
<!--              <td>-->
<!--                <h2>Miscellanea</h2>-->
<!--              </td>-->
<!--            </tr>-->
<!--          </tbody></table>-->
<!--          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>-->
            
           



						
						
           

          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:0px">
                <br>
                <p style="text-align:center;font-size:small;">
                  This home page is adapted from the template of  <a href="https://github.com/jonbarron/jonbarron_website">Jon Barron's website</a>.
                </p>
              </td>
            </tr>
          </tbody></table>
        </td>
      </tr>
    </table>
  </body>
</html>

<div style="display: flex; justify-content: center; align-items: center; height: 5vh;">
    <div style="width: 0px; height: 0px; overflow: hidden;">
        <script type="text/javascript" id="clstr_globe" src="//clustrmaps.com/globe.js?d=A9ee5Joff_ZY_f35ALe-JrXUQyPM_i1OCuK0wh4A70Y"></script>
    </div>
</div>


